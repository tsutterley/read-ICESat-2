{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples to visualize ICESat-2 ATL03 data\n",
    "This notebook uses standard python tools to demonstrate some basic visualization of the ICESat-2 ATL03 product  \n",
    "[NSIDC: ICESat-2 Level-2 Products](https://nsidc.org/data/icesat-2/products/level-2)  \n",
    "\n",
    "The primary and secondary instrumentation onboard the ICESat-2 observatory are the Advanced Topographic Laser Altimeter System (ATLAS, a photon-counting laser altimeter), the global positioning system (GPS) and the star cameras. \n",
    "Data from these instruments are combined to create three primary measurements: the time of flight of a photon transmitted and received from ATLAS, the position of the satellite in space, and the pointing vector of the satellite during the transmission of photons. \n",
    "These three measurements are used to create ATL03, the geolocated photon product of ICESat-2.  \n",
    "\n",
    "#### ATL03 - Global Geolocated Photon Data\n",
    "- Precise latitude, longitude and elevation for every received photon, arranged by beam in the along-track direction  \n",
    "- Photons classified by signal vs. background, as well as by surface type (land ice, sea ice, land, ocean), including all geophysical corrections  \n",
    "\n",
    "More information about ATL03 can be found in the Algorithm Theoretical Basis Documents (ATBDs) provided by the ICESat-2 project:  \n",
    "- [ATL03: Global Geolocated Photon Data](https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL03_ATBD_r002.pdf)  \n",
    "- [ATL03g: Received photon geolocation](https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/ICESat2_ATL03g_ATBD_r002.pdf)  \n",
    "- [ATL03a: Atmospheric Delay Corrections](https://icesat-2.gsfc.nasa.gov/sites/default/files/page_files/I2_ATL03A_ATBD.pdf)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load necessary modules for running the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.animation as animation\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import icesat2_toolkit as is2tk\n",
    "from yapc.classify_photons import classify_photons\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download ATL03 HDF5 file from NSIDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATL03_url = ['https://n5eil01u.ecs.nsidc.org','ATLAS','ATL03.004',\n",
    "    '2019.11.15','ATL03_20191115042423_07520512_004_01.h5']\n",
    "local = is2tk.utilities.get_data_path(['data',ATL03_url[-1]])\n",
    "# check if local file is available\n",
    "if not os.access(local, os.F_OK):\n",
    "    # download ATL03 file from NSIDC\n",
    "    is2tk.utilities.from_nsidc(ATL03_url,local=local,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read ATL03 HDF5 file and extract variables of interest\n",
    "Let's at a granule that crosses Antarctica. The structure of the file has six groups for each beam, data describing the responses of the ATLAS instrument, ancillary data for correcting and transforming the ATL03 data, and a group of metadata.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ICESat-2 ATL03 data\n",
    "IS2_atl03_mds,IS2_atl03_attrs,IS2_atl03_beams = is2tk.io.ATL03.read_granule(local,ATTRIBUTES=True)\n",
    "\n",
    "# extract parameters from ICESat-2 ATLAS HDF5 file name\n",
    "rx = re.compile(r'(processed_)?(ATL\\d{2})_(\\d{4})(\\d{2})(\\d{2})(\\d{2})'\n",
    "    r'(\\d{2})(\\d{2})_(\\d{4})(\\d{2})(\\d{2})_(\\d{3})_(\\d{2})(.*?).h5$')\n",
    "SUB,PRD,YY,MM,DD,HH,MN,SS,TRK,CYCL,GRAN,RL,VERS,AUX = rx.findall(local).pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract photon data and calculate means along overlapping 40m segments\n",
    "\n",
    "ATL03 contains most of the data needed to create the higher level data products (such as the ATL06 land ice product).  Here, we will calculate the mean elevation of 40m segments for each beam to be used for later visualization.  These mean segment elevations will not be corrected for transmit pulse shape biases or first photon biases as compared to the higher level data products (more about that later).\n",
    "\n",
    "The ATL03 photon events will have a confidence level flag associated with it for a given surface type:  \n",
    "- -2: possible Transmit Echo Path photons  \n",
    "- -1: events not associated with a specific surface type  \n",
    "- 0: noise  \n",
    "- 1: buffer but algorithm classifies as background  \n",
    "- 2: low  \n",
    "- 3: medium  \n",
    "- 4: high  \n",
    "\n",
    "In the confidence level matrix, the column of each surface types is:   \n",
    "- 0: Land  \n",
    "- 1: Ocean  \n",
    "- 2: Sea Ice  \n",
    "- 3: Land Ice  \n",
    "- 4: Inland Water  \n",
    "\n",
    "The level of confidence of a given photon event (PE) may vary based on the surface type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# variables of interest for generating corrected elevation estimates\n",
    "Segment_ID = {}\n",
    "Segment_Index_begin = {}\n",
    "Segment_PE_count = {}\n",
    "Segment_Distance = {}\n",
    "Segment_Length = {}\n",
    "# mean geolocation, height and delta time\n",
    "Segment_Lon = {}\n",
    "Segment_Lat = {}\n",
    "Segment_Elev = {}\n",
    "Segment_Time = {}\n",
    "# background photon rate\n",
    "background_rate = {}\n",
    "# photon event signal-to-noise ratio from photon classifier\n",
    "Segment_Photon_SNR = {}\n",
    "\n",
    "# number of GPS seconds between the GPS epoch\n",
    "# and ATLAS Standard Data Product (SDP) epoch\n",
    "atlas_sdp_gps_epoch, = IS2_atl03_mds['ancillary_data']['atlas_sdp_gps_epoch']\n",
    "\n",
    "# for each input beam within the file\n",
    "for gtx in sorted(IS2_atl03_beams):\n",
    "    # data and attributes for beam gtx\n",
    "    val = IS2_atl03_mds[gtx]\n",
    "    attrs = IS2_atl03_attrs[gtx]\n",
    "    # ATL03 Segment ID\n",
    "    Segment_ID[gtx] = val['geolocation']['segment_id']\n",
    "    n_seg = len(Segment_ID[gtx])\n",
    "    # number of photon events\n",
    "    n_pe, = val['heights']['delta_time'].shape\n",
    "    # first photon in the segment (convert to 0-based indexing)\n",
    "    Segment_Index_begin[gtx] = val['geolocation']['ph_index_beg'] - 1\n",
    "    # number of photon events in the segment\n",
    "    Segment_PE_count[gtx] = val['geolocation']['segment_ph_cnt']\n",
    "    # along-track distance for each ATL03 segment\n",
    "    Segment_Distance[gtx] = val['geolocation']['segment_dist_x']\n",
    "    # along-track length for each ATL03 segment\n",
    "    Segment_Length[gtx] = val['geolocation']['segment_length']\n",
    "    # Transmit time of the reference photon\n",
    "    delta_time = val['geolocation']['delta_time']\n",
    "    # interpolate background photon rate based on 50-shot summation\n",
    "    background_delta_time = val['bckgrd_atlas']['delta_time']\n",
    "    SPL = scipy.interpolate.UnivariateSpline(background_delta_time,\n",
    "        val['bckgrd_atlas']['bckgrd_rate'],k=3,s=0)\n",
    "    background_rate[gtx] = SPL(delta_time)\n",
    "\n",
    "    # along-track and across-track distance for photon events\n",
    "    x_atc = val['heights']['dist_ph_along']\n",
    "    y_atc = val['heights']['dist_ph_across']\n",
    "    # photon event heights\n",
    "    h_ph = val['heights']['h_ph'][:]\n",
    "    # digital elevation model interpolated to photon events\n",
    "    dem_h = np.zeros((n_pe))\n",
    "    # for each 20m segment\n",
    "    for j,_ in enumerate(Segment_ID[gtx]):\n",
    "        # index for 20m segment j\n",
    "        idx = Segment_Index_begin[gtx][j]\n",
    "        # skip segments with no photon events\n",
    "        if (idx < 0):\n",
    "            continue\n",
    "        # number of photons in 20m segment\n",
    "        cnt = Segment_PE_count[gtx][j]\n",
    "        # add segment distance to along-track coordinates\n",
    "        x_atc[idx:idx+cnt] += Segment_Distance[gtx][j]\n",
    "        # interpolate digital elevation model to photon events\n",
    "        dem_h[idx:idx+cnt] = val['geophys_corr']['dem_h'][j]\n",
    "\n",
    "    # iterate over ATLAS major frames\n",
    "    photon_mframes = val['heights']['pce_mframe_cnt']\n",
    "    # background ATLAS group variables are based upon 50-shot summations\n",
    "    # PCE Major Frames are based upon 200-shot summations\n",
    "    pce_mframe_cnt = val['bckgrd_atlas']['pce_mframe_cnt']\n",
    "    # find unique major frames and their indices within background ATLAS group\n",
    "    # (there will 4 background ATLAS time steps for nearly every major frame)\n",
    "    unique_major_frames,unique_index = np.unique(pce_mframe_cnt,return_index=True)\n",
    "    # number of unique major frames in granule for beam\n",
    "    major_frame_count = len(unique_major_frames)\n",
    "    # height of each telemetry band for a major frame\n",
    "    tlm_height = {}\n",
    "    tlm_height['band1'] = val['bckgrd_atlas']['tlm_height_band1']\n",
    "    tlm_height['band2'] = val['bckgrd_atlas']['tlm_height_band2']\n",
    "    # elevation above ellipsoid of each telemetry band for a major frame\n",
    "    tlm_top = {}\n",
    "    tlm_top['band1'] = val['bckgrd_atlas']['tlm_top_band1']\n",
    "    tlm_top['band2'] = val['bckgrd_atlas']['tlm_top_band2']\n",
    "    # buffer to telemetry band to set as valid\n",
    "    tlm_buffer = 100.0\n",
    "    # flag denoting photon events as possible TEP\n",
    "    if (int(RL) < 4):\n",
    "        isTEP = np.any((val['heights']['signal_conf_ph'][:]==-2),axis=1)\n",
    "    else:\n",
    "        isTEP = (val['heights']['quality_ph'][:] == 3)\n",
    "    # photon event weights and signal-to-noise ratio\n",
    "    pe_weights = np.zeros((n_pe),dtype=np.float64)\n",
    "    Segment_Photon_SNR[gtx] = np.zeros((n_pe),dtype=int)\n",
    "    # run for each major frame\n",
    "    for iteration,idx in enumerate(unique_index):\n",
    "        # sum of telemetry band widths for major frame\n",
    "        h_win_width = 0.0\n",
    "        # check that each telemetry band is close to DEM\n",
    "        for b in ['band1','band2']:\n",
    "            # bottom of the telemetry band for major frame\n",
    "            tlm_bot_band = tlm_top[b][idx] - tlm_height[b][idx]\n",
    "            if np.any((dem_h[i1[i2]] >= (tlm_bot_band-tlm_buffer)) &\n",
    "                (dem_h[i1[i2]] <= (tlm_top[b][idx]+tlm_buffer))):\n",
    "                # add telemetry height to window width\n",
    "                h_win_width += tlm_height[b][idx]\n",
    "        # photon indices for major frame (buffered by 1 frame on each side)\n",
    "        # do not use possible TEP photons in photon classification\n",
    "        i1, = np.nonzero((photon_mframes >= unique_major_frames[iteration]-1) &\n",
    "            (photon_mframes <= unique_major_frames[iteration]+1) &\n",
    "            np.logical_not(isTEP))\n",
    "        # indices for the major frame within the buffered window\n",
    "        i2, = np.nonzero(photon_mframes[i1] == unique_major_frames[iteration])\n",
    "        # calculate photon event weights\n",
    "        pe_weights[i1[i2]] = classify_photons(x_atc[i1], h_ph[i1],\n",
    "            h_win_width, i2, K=0, min_knn=5, min_ph=3, min_xspread=1.0,\n",
    "            min_hspread=0.01, win_x=15.0, win_h=6.0, method='linear')\n",
    "\n",
    "    # photon event weights scaled to a single byte\n",
    "    weight_ph = np.array(255*pe_weights,dtype=np.uint8)\n",
    "    # verify photon event weights\n",
    "    np.clip(weight_ph, 0, 255, out=weight_ph)\n",
    "\n",
    "    # allocate for segment means\n",
    "    fill_value = attrs['geolocation']['sigma_h']['_FillValue']\n",
    "    # mean longitude of each segment high-confidence photons\n",
    "    Segment_Lon[gtx] = np.ma.zeros((n_seg),fill_value=fill_value)\n",
    "    Segment_Lon[gtx].data[:] = Segment_Lon[gtx].fill_value\n",
    "    Segment_Lon[gtx].mask = np.ones((n_seg),dtype=bool)\n",
    "    # mean longitude of each segment high-confidence photons\n",
    "    Segment_Lat[gtx] = np.ma.zeros((n_seg),fill_value=fill_value)\n",
    "    Segment_Lat[gtx].data[:] = Segment_Lat[gtx].fill_value\n",
    "    Segment_Lat[gtx].mask = np.ones((n_seg),dtype=bool)\n",
    "    # mean height of each segment high-confidence photons\n",
    "    Segment_Elev[gtx] = np.ma.zeros((n_seg),fill_value=fill_value)\n",
    "    Segment_Elev[gtx].data[:] = Segment_Elev[gtx].fill_value\n",
    "    Segment_Elev[gtx].mask = np.ones((n_seg),dtype=bool)\n",
    "    # mean time of each segment high-confidence photons\n",
    "    Segment_Time[gtx] = np.ma.zeros((n_seg),fill_value=fill_value)\n",
    "    Segment_Time[gtx].data[:] = Segment_Time[gtx].fill_value\n",
    "    Segment_Time[gtx].mask = np.ones((n_seg),dtype=bool)\n",
    "    \n",
    "    # iterate over ATL03 segments to calculate 40m means\n",
    "    # in ATL03 1-based indexing: invalid == 0\n",
    "    # here in 0-based indexing: invalid == -1   \n",
    "    segment_indices, = np.nonzero((Segment_Index_begin[gtx][:-1] >= 0) &\n",
    "        (Segment_Index_begin[gtx][1:] >= 0))\n",
    "    for j in segment_indices:\n",
    "        # index for segment j\n",
    "        idx = Segment_Index_begin[gtx][j]\n",
    "        # number of photons in segment (use 2 ATL03 segments)\n",
    "        c1 = np.copy(Segment_PE_count[gtx][j])\n",
    "        c2 = np.copy(Segment_PE_count[gtx][j+1])\n",
    "        cnt = c1 + c2\n",
    "        # time of each Photon event (PE)\n",
    "        segment_delta_times = val['heights']['delta_time'][idx:idx+cnt]\n",
    "        gps_seconds = atlas_sdp_gps_epoch + segment_delta_times\n",
    "        time_leaps = is2tk.time.count_leap_seconds(gps_seconds)\n",
    "        # Photon event lat/lon and elevation (WGS84)\n",
    "        segment_heights = h_ph[idx:idx+cnt].copy()\n",
    "        segment_lats = val['heights']['lat_ph'][idx:idx+cnt]\n",
    "        segment_lons = val['heights']['lon_ph'][idx:idx+cnt]\n",
    "        # calculate segment time in Julian days (UTC)\n",
    "        segment_times = 2444244.5 + (gps_seconds - time_leaps)/86400.0           \n",
    "        # Photon event channel and identification\n",
    "        ID_channel = val['heights']['ph_id_channel'][idx:idx+cnt]\n",
    "        ID_pulse = val['heights']['ph_id_pulse'][idx:idx+cnt]\n",
    "        n_pulses = np.unique(ID_pulse).__len__()\n",
    "        frame_number = val['heights']['pce_mframe_cnt'][idx:idx+cnt]\n",
    "        # along-track X and Y coordinates\n",
    "        distance_along_X = np.copy(x_atc[idx:idx+cnt])\n",
    "        distance_along_Y = np.copy(y_atc[idx:idx+cnt])\n",
    "        # check the spread of photons along-track (must be > 20m)\n",
    "        along_X_spread = distance_along_X.max() - distance_along_X.min()\n",
    "        # Along-track distance between 2 segments\n",
    "        X_atc = Segment_Distance[gtx][j] + Segment_Length[gtx][j]        \n",
    "        # check confidence level associated with each photon event\n",
    "        # -2: TEP\n",
    "        # -1: Events not associated with a specific surface type\n",
    "        #  0: noise\n",
    "        #  1: buffer but algorithm classifies as background\n",
    "        #  2: low\n",
    "        #  3: medium\n",
    "        #  4: high\n",
    "        # Signal classification confidence for land ice\n",
    "        # 0=Land; 1=Ocean; 2=SeaIce; 3=LandIce; 4=InlandWater\n",
    "        ice_sig_conf = val['heights']['signal_conf_ph'][idx:idx+cnt,3]\n",
    "        ice_sig_low_count = np.count_nonzero(ice_sig_conf >= 1)\n",
    "        # indices of TEP classified photons\n",
    "        ice_sig_tep_pe, = np.nonzero(ice_sig_conf == -2)\n",
    "        # photon event weights from photon classifier\n",
    "        segment_weights = weight_ph[idx:idx+cnt]\n",
    "        snr_norm = np.max(segment_weights)\n",
    "        # photon event signal-to-noise ratio from photon classifier\n",
    "        photon_snr = np.zeros((cnt),dtype=int)\n",
    "        if (snr_norm > 0):\n",
    "            photon_snr[:] = 100.0*segment_weights/snr_norm\n",
    "        # copy signal to noise ratio for photons\n",
    "        Segment_Photon_SNR[gtx][idx:idx+cnt] = np.copy(photon_snr)\n",
    "        # photon confidence levels from classifier\n",
    "        pe_sig_conf = np.zeros((cnt),dtype=int)\n",
    "        # calculate confidence levels from photon classifier\n",
    "        pe_sig_conf[photon_snr >= 25] = 2\n",
    "        pe_sig_conf[photon_snr >= 60] = 3\n",
    "        pe_sig_conf[photon_snr >= 80] = 4\n",
    "        # copy classification for TEP photons\n",
    "        pe_sig_conf[ice_sig_tep_pe] = -2\n",
    "        pe_sig_low_count = np.count_nonzero(pe_sig_conf > 1)\n",
    "        # check if segment has photon events classified \n",
    "        # for land ice that are at least low-confidence threshold\n",
    "        # and that the spread of photons is greater than 20m\n",
    "        if (pe_sig_low_count > 10) & (along_X_spread > 20):\n",
    "            # find photon events that are high-confidence\n",
    "            ii, = np.nonzero(pe_sig_conf >= 4)\n",
    "            # calculate mean elevation (without iterations)\n",
    "            # NOTE that the segment elevations will NOT be corrected\n",
    "            # for transmit pulse shape biases or first photon biases\n",
    "            Segment_Elev[gtx].data[j] = is2tk.fit.fit_geolocation(\n",
    "                segment_heights[ii], distance_along_X[ii], X_atc)\n",
    "            Segment_Elev[gtx].mask[j] = False\n",
    "            # calculate geolocation and time of 40m segment center\n",
    "            Segment_Lon[gtx].data[j] = is2tk.fit.fit_geolocation(\n",
    "                segment_lons[ii], distance_along_X[ii], X_atc)\n",
    "            Segment_Lon[gtx].mask[j] = False\n",
    "            Segment_Lat[gtx].data[j] = is2tk.fit.fit_geolocation(\n",
    "                segment_lats[ii], distance_along_X[ii], X_atc)\n",
    "            Segment_Lat[gtx].mask[j] = False\n",
    "            Segment_Time[gtx].data[j] = is2tk.fit.fit_geolocation(\n",
    "                segment_times[ii], distance_along_X[ii], X_atc)\n",
    "            Segment_Time[gtx].mask[j] = False\n",
    "    # clear photon classifier variables for beam group\n",
    "    pe_weights = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a scatter plot of photon elevations vs ATL03 segment ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter plot of photon data for all beams\n",
    "ax = {}\n",
    "f1,((ax['gt1l'],ax['gt1r']),(ax['gt2l'],ax['gt2r']),(ax['gt3l'],ax['gt3r'])) = \\\n",
    "    plt.subplots(num=1,nrows=3,ncols=2,sharex=True,sharey=True,figsize=(7,10))\n",
    "for gtx,ax1 in ax.items():\n",
    "    # data for beam gtx\n",
    "    val = IS2_atl03_mds[gtx]\n",
    "    # segment ID of each photon event\n",
    "    IDs = np.zeros_like(val['heights']['h_ph'],dtype=int)\n",
    "    for j,idx in enumerate(Segment_Index_begin[gtx]):\n",
    "        # number of photons in segment\n",
    "        cnt = Segment_PE_count[gtx][j]\n",
    "        # get segment ID of each photon event\n",
    "        IDs[idx:idx+cnt] = Segment_ID[gtx][j]*np.ones((cnt))\n",
    "    # signal classification confidence\n",
    "    ice_sig_conf = val['heights']['signal_conf_ph'][:,3]        \n",
    "    # plot all elevations mapped to segment ID\n",
    "    # Photon event lat/lon and elevation (WGS84)\n",
    "    ax1.plot(IDs,val['heights']['h_ph'],',',c='0.5')\n",
    "    # find TEP events and plot in different color\n",
    "    isTEP, = np.nonzero(ice_sig_conf == -2)\n",
    "    ax1.plot(IDs[isTEP],val['heights']['h_ph'][isTEP],',',c='red')\n",
    "    # plot 40m mean elevation of high confidence photons\n",
    "    ax1.plot(Segment_ID[gtx],Segment_Elev[gtx],',',c='darkorchid')\n",
    "    # set title as beam\n",
    "    ax1.set_title(gtx)\n",
    "    # adjust ticks\n",
    "    ax1.get_xaxis().set_tick_params(which='both',direction='in')\n",
    "    ax1.get_yaxis().set_tick_params(which='both',direction='in')\n",
    "# add x and y labels\n",
    "for gtx in ['gt3l','gt3r']:\n",
    "    ax[gtx].set_xlabel('Segment ID')\n",
    "for gtx in ['gt1l','gt2l','gt3l']:\n",
    "    ax[gtx].set_ylabel('Elevation above WGS84 Ellipsoid [m]')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular set of data approaches the grounding line near Thwaites Glacier in West Antarctica, has some photon events that are impacted by the presence of clouds (highly scattered lower confidence photon events), and has some possible Transmitter Echo Photons (TEP) (the red curved line of anomalous photon events in gt2r and gt3r).  These are [things to be aware of when analyzing photon event data from ATL03](https://nsidc.org/sites/nsidc.org/files/technical-references/ATL03_Known_Issues_May2019.pdf).  \n",
    "\n",
    "The ATLAS instrument decides whether or not to telemeter packets of received photons back as data.  ATLAS uses a digital elevation model (DEM) and a few rules to decide whether to transmit large blocks of data to NASA.  The telemetry bands are evident by the spread of low confidence photon events around the surface for each beam.  \n",
    "\n",
    "Photon events in ATL03 can come to the ATLAS receiver in a few different ways:  \n",
    "- Many photons come from the sun either by reflecting off clouds or the land surface.  These photon events are spread in a random distribution along the telemetry band.  In ATL03, a large majority of these \"background\" photon events are classified, but some may be incorrectly classified as signal.  \n",
    "- Some photons are from the ATLAS instrument that have reflected off clouds. These photons can be clustered together or widely dispersed depending on the properties of the cloud and a few other variables.  \n",
    "- Some photons will be returns from the [Transmit Echo Path (TEP)](https://nsidc.org/sites/nsidc.org/files/technical-references/ATL03_Known_Issues_May2019.pdf)  \n",
    "- Some photons are from the ATLAS instrument that have reflected off the surface (our signal photons).  \n",
    "\n",
    "There will be photons transmitted by the ATLAS instrument will never be recorded back.  The vast majority of these photons never reached the ATLAS instrument again  (only about 10 out of the 10<sup>14</sup> photons transmitted are received), but some are not detected due to the \"dead time\" of the instrument.  This can create a bias towards the first photons that were received by the instrument.  This first photon bias (FPB) is estimated in the higher level data products.  \n",
    "\n",
    "The transmitted pulse is also not symmetric in time, which can introduce a bias when calculating average surfaces.  The magnitude of this bias depends on the shape of the transmitted waveform, the width of the window used to calculate the average surface, and the slope and roughness of the surface that broadens the return pulse.  This transmit-pulse shape bias is also estimated in the higher level data products.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a scatter plot of photon elevations vs time\n",
    "To show the impacts of clouds in more detail, we can investigate the confidence of each photon event for a cloud impacted beam.  For this file, the cloud is situated over the sea surface and does not have an associated confidence for land ice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter plot of photon data versus time\n",
    "f2,ax2 = plt.subplots(num=2,nrows=2,sharex=True,figsize=(10,10))\n",
    "\n",
    "# data for beam gtx\n",
    "gtx = 'gt2r'\n",
    "val = IS2_atl03_mds[gtx]\n",
    "\n",
    "# time of each Photon event (PE)\n",
    "delta_time = val['heights']['delta_time'][:]\n",
    "gps_seconds = atlas_sdp_gps_epoch + delta_time\n",
    "time_leaps = is2tk.time.count_leap_seconds(gps_seconds)\n",
    "# calculate time in Modified Julian Days (UTC)\n",
    "# (days since 1858-11-17T00:00:00)\n",
    "MJD = 44244.0 + (gps_seconds - time_leaps)/86400.0   \n",
    "\n",
    "# check confidence level associated with each photon event\n",
    "# -1: Events not associated with a specific surface type\n",
    "#  0: noise\n",
    "#  1: buffer but algorithm classifies as background\n",
    "#  2: low\n",
    "#  3: medium\n",
    "#  4: high\n",
    "# Signal classification confidence for land ice\n",
    "# 0=Land; 1=Ocean; 2=SeaIce; 3=LandIce; 4=InlandWater\n",
    "ice_sig_conf = val['heights']['signal_conf_ph'][:,3]\n",
    "# find possible TEP events\n",
    "isTEP, = np.nonzero(ice_sig_conf == -2)\n",
    "# find different surface classification photon events\n",
    "stype, = np.nonzero(ice_sig_conf == -1)\n",
    "# background and buffer photons\n",
    "bg, = np.nonzero((ice_sig_conf == 0) | (ice_sig_conf == 1))\n",
    "# find photon events of progressively higher confidence\n",
    "lc, = np.nonzero(ice_sig_conf == 2)\n",
    "mc, = np.nonzero(ice_sig_conf == 3)\n",
    "hc, = np.nonzero(ice_sig_conf == 4)\n",
    "# Photon event time and elevation (WGS84)\n",
    "ax2[0].plot(MJD[isTEP],val['heights']['h_ph'][isTEP],marker='.',\n",
    "    markersize=0.1,lw=0,color='red',label='TEP')\n",
    "ax2[0].plot(MJD[stype],val['heights']['h_ph'][stype],marker='.',\n",
    "    markersize=0.1,lw=0,color='0.2',label='Surface Classification')\n",
    "ax2[0].plot(MJD[bg],val['heights']['h_ph'][bg],marker='.',\n",
    "    markersize=0.1,lw=0,color='0.5',label='Background')\n",
    "ax2[0].plot(MJD[lc],val['heights']['h_ph'][lc],marker='.',\n",
    "    markersize=0.1,lw=0,color='darkorange',label='Low Confidence')\n",
    "ax2[0].plot(MJD[mc],val['heights']['h_ph'][mc],marker='.',\n",
    "    markersize=0.1,lw=0,color='mediumseagreen',label='Medium Confidence')\n",
    "ax2[0].plot(MJD[hc],val['heights']['h_ph'][hc],marker='.',\n",
    "    markersize=0.1,lw=0,color='darkorchid',label='High Confidence')\n",
    "\n",
    "# Photon event classifier\n",
    "isort = np.argsort(Segment_Photon_SNR[gtx])\n",
    "sc = ax2[1].scatter(MJD[isort],val['heights']['h_ph'][isort],\n",
    "    c=Segment_Photon_SNR[gtx][isort],s=0.1)\n",
    "# add colorbar for scatter plot\n",
    "cax = f2.add_axes([0.075, 0.080, 0.325, 0.02])\n",
    "# add extension triangles to upper and lower bounds\n",
    "# pad = distance from main plot axis\n",
    "# shrink = percent size of colorbar\n",
    "# aspect = lengthXwidth aspect of colorbar\n",
    "cbar = f2.colorbar(sc, cax=cax, extend='both', extendfrac=0.0375,\n",
    "    drawedges=False, orientation='horizontal')\n",
    "# rasterized colorbar to remove lines\n",
    "cbar.solids.set_rasterized(True)\n",
    "# Add label to the colorbar\n",
    "cbar.ax.set_xlabel('Photon Classifier SNR')\n",
    "cbar.ax.xaxis.set_label_position('top')\n",
    "# ticks lines all the way across\n",
    "cbar.ax.tick_params(which='both',width=1,length=11,direction=\"in\")\n",
    "\n",
    "# set title and labels\n",
    "ax2[1].set_xlabel('Time [MJD]')\n",
    "ax2[0].set_ylabel('Elevation above WGS84 Ellipsoid [m]')\n",
    "ax2[1].set_ylabel('Elevation above WGS84 Ellipsoid [m]')\n",
    "ax2[0].set_title(gtx)\n",
    "# create legend\n",
    "lgd = ax2[0].legend(loc=3,frameon=False)\n",
    "lgd.get_frame().set_alpha(1.0)\n",
    "for line in lgd.get_lines():\n",
    "    line.set_linewidth(6)\n",
    "# adjust ticks\n",
    "for axis in ax2:\n",
    "    axis.get_xaxis().set_tick_params(which='both',direction='in')\n",
    "    axis.get_yaxis().set_tick_params(which='both',direction='in')\n",
    "# adjust the figure axes\n",
    "f2.subplots_adjust(left=0.07, right=0.98, bottom=0.05, top=0.95, hspace=0.05)\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 40m mean elevations on a map projection\n",
    "Here, we visualize our 40m segment elevations spatially.  The surface elevation decreases from the interior of the ice sheet as we approach the coast.  The calculated surface extends over the ocean because the ATL03 classification scheme uses a buffered mask to fully encapsulate the ice sheet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ATL03 photon event elevations on a map projection\n",
    "projection = ccrs.Stereographic(central_longitude=0.0,\n",
    "    central_latitude=-90,true_scale_latitude=-71.0)\n",
    "f3,ax3 = plt.subplots(num=3,figsize=(7,5),\n",
    "    subplot_kw=dict(projection=projection))\n",
    "# scatter plot parameters\n",
    "vmin,vmax=(0,2000)\n",
    "cmap = copy.copy(cm.viridis_r)\n",
    "cmap.set_bad(alpha=0.0)\n",
    "# for each beam\n",
    "for gtx in ['gt1l','gt1r','gt2l','gt2r','gt3l','gt3r']:\n",
    "    sc = ax3.scatter(Segment_Lon[gtx],Segment_Lat[gtx],\n",
    "        c=Segment_Elev[gtx], s=0.1, cmap=cmap,\n",
    "        vmin=vmin, vmax=vmax, transform=ccrs.PlateCarree())\n",
    "ax3.set_aspect('equal', adjustable='box')\n",
    "ax3.get_xaxis().set_ticks([])\n",
    "ax3.get_yaxis().set_ticks([])    \n",
    "# add colorbar\n",
    "cbar = f2.colorbar(sc,ax=ax3,extend='both',extendfrac=0.0375,\n",
    "    pad=0.03, drawedges=False)\n",
    "cbar.solids.set_rasterized(True)\n",
    "cbar.ax.tick_params(which='both', length=16, width=1, direction='in')\n",
    "cbar.ax.set_ylabel('Elevation above WGS84 Ellipsoid')\n",
    "cbar.ax.set_xlabel('m')\n",
    "cbar.ax.xaxis.set_label_coords(0.50,1.04)\n",
    "# add cartopy coastlines and zoom out\n",
    "ax3.coastlines('50m')\n",
    "ax3.set_extent([-180,180,-90,-60],crs=ccrs.PlateCarree())\n",
    "# adjust subplot within figure\n",
    "f3.subplots_adjust(left=0.02,right=0.85,bottom=0.02,top=0.95)\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create animation of histograms for a beam\n",
    "Here, we will look at the photons for a series of 40m segments from a single beam.  The histogram of data here is tightly peaked along the surface of the ice sheet.  Scenarios with rougher or more complex terrain, different surface albedos or different rates of solar insolation can all impact the resultant histograms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histogram of the photon heights\n",
    "f4 = plt.figure(num=4,figsize=(11,5))\n",
    "gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 2])\n",
    "ax4 = {}\n",
    "ax4[0] = plt.subplot(gs[0])\n",
    "ax4[1] = plt.subplot(gs[1], sharey=ax4[0])\n",
    "# polar stereographic projection\n",
    "projection = ccrs.Stereographic(central_longitude=0.0,\n",
    "    central_latitude=-90,true_scale_latitude=-71.0)\n",
    "ax4[2] = plt.subplot(gs[2], projection=projection)\n",
    "\n",
    "# beam parameters\n",
    "gtx = 'gt1l'\n",
    "val = IS2_atl03_mds[gtx]\n",
    "# number of ATL03 segments\n",
    "n_seg = len(Segment_ID[gtx])\n",
    "\n",
    "# histogram parameters\n",
    "w = 0.2\n",
    "vmin,vmax=(900,1900)\n",
    "b1 = np.arange(vmin,vmax+w,w)\n",
    "b2 = (b1[1:] + b1[0:-1])/2.0\n",
    "\n",
    "# histogram of photon height\n",
    "l1, = ax4[0].plot([],[],color='mediumseagreen')\n",
    "l2, = ax4[0].plot([],[],color='darkorchid')\n",
    "ax4[0].set_xlim(0,80)\n",
    "ax4[0].set_ylim(vmin,vmax)\n",
    "# plot of photon height\n",
    "l3, = ax4[1].plot([],[],'.',color='mediumseagreen')\n",
    "l4, = ax4[1].plot([],[],'.',color='darkorchid')\n",
    "ax4[1].set_xlim(0,40)\n",
    "# map of lat/lon location\n",
    "ax4[2].plot(Segment_Lon[gtx], Segment_Lat[gtx],\n",
    "    transform=ccrs.PlateCarree(), color='b', zorder=0)\n",
    "for gt in sorted(set(['gt1l','gt2l','gt3l']) - set([gtx])):\n",
    "    ax4[2].plot(Segment_Lon[gt], Segment_Lat[gt],\n",
    "        transform=ccrs.PlateCarree(), color='0.5', zorder=0)\n",
    "l5, = ax4[2].plot([], [], '.', transform=ccrs.PlateCarree(),\n",
    "    color='darkorange', ms=5, zorder=1)\n",
    "# set x and y labels\n",
    "ax4[0].set_xlabel('Photon Event Count')\n",
    "ax4[0].set_ylabel('Elevation above WGS84 Ellipsoid [m]')\n",
    "ax4[1].set_xlabel('Along-Track Distance [m]')\n",
    "# adjust ticks\n",
    "plt.setp(ax4[1].get_yticklabels(), visible=False)\n",
    "ax4[0].get_xaxis().set_tick_params(which='both',direction='in')\n",
    "ax4[0].get_yaxis().set_tick_params(which='both',direction='in')\n",
    "ax4[1].get_xaxis().set_tick_params(which='both',direction='in')\n",
    "ax4[1].get_yaxis().set_tick_params(which='both',direction='in')\n",
    "# add cartopy coastlines and zoom out\n",
    "ax4[2].coastlines('50m')\n",
    "ax4[2].set_extent([-180,180,-90,-60],crs=ccrs.PlateCarree())\n",
    "# set title as beam\n",
    "ttl = f4.suptitle(None)\n",
    "# adjust subplot within figure\n",
    "f4.subplots_adjust(left=0.1,right=0.95,bottom=0.1,top=0.925,wspace=0.1)\n",
    "\n",
    "# animate every 50th segment\n",
    "def animate_segments(i):\n",
    "    # index for segment j\n",
    "    j = 50*i\n",
    "    idx = val['geolocation']['ph_index_beg'][j] - 1\n",
    "    # number of photons in segment (use 2 ATL03 segments)\n",
    "    c1 = np.copy(val['geolocation']['segment_ph_cnt'][j])\n",
    "    c2 = np.copy(val['geolocation']['segment_ph_cnt'][j+1])\n",
    "    cnt = c1 + c2\n",
    "    # along-track X and Y coordinates    \n",
    "    distance_along_X = np.copy(val['heights']['dist_ph_along'][idx:idx+cnt])\n",
    "    distance_along_X[c1:] += Segment_Length[gtx][j]\n",
    "    distance_along_Y = np.copy(val['heights']['dist_ph_across'][idx:idx+cnt])\n",
    "    # photon height for segment\n",
    "    h_ph = val['heights']['h_ph'][idx:idx+cnt]\n",
    "    # latitude and longitude of segment\n",
    "    segment_lats = val['heights']['lat_ph'][idx:idx+cnt]\n",
    "    segment_lons = val['heights']['lon_ph'][idx:idx+cnt]\n",
    "    # land ice signal confidence for segment\n",
    "    ice_sig_conf = val['heights']['signal_conf_ph'][idx:idx+cnt,3]\n",
    "    bg, = np.nonzero(ice_sig_conf <= 1)\n",
    "    mc, = np.nonzero(ice_sig_conf >= 2)\n",
    "    # signal to noise ratio for photons in segment\n",
    "    photon_snr = Segment_Photon_SNR[gtx][idx:idx+cnt]\n",
    "    # calculate confidence levels from photon classifier\n",
    "    bg, = np.nonzero(photon_snr < 60)\n",
    "    mc, = np.nonzero(photon_snr >= 60)\n",
    "    # histogram using numpy\n",
    "    hbg,bbg = np.histogram(h_ph[bg],bins=b1)\n",
    "    hmc,bmc = np.histogram(h_ph[mc],bins=b1)\n",
    "    # set data for each empty plot\n",
    "    l1.set_data(hbg,b2)\n",
    "    l2.set_data(hmc,b2)\n",
    "    l3.set_data(distance_along_X[bg],h_ph[bg])\n",
    "    l4.set_data(distance_along_X[mc],h_ph[mc])\n",
    "    l5.set_data(segment_lons, segment_lats)\n",
    "    # set title text\n",
    "    args = (PRD,YY,MM,DD,TRK,gtx,Segment_ID[gtx][j+1])\n",
    "    ttl.set_text(('{0} {1}-{2}-{3}\\tTrack {4}\\tBeam {5}'\n",
    "        '\\tSegment {6:d}').format(*args).expandtabs())\n",
    "\n",
    "# set animation\n",
    "anim = animation.FuncAnimation(f4, animate_segments, frames=300)\n",
    "%matplotlib inline\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
